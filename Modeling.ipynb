{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51db2ced",
   "metadata": {},
   "source": [
    "# Weather Big Data Contest 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5557c690",
   "metadata": {},
   "source": [
    "### Yonsei University - Hyunjoo Kim, Jiwon Lim, Hyejin Eum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f56188",
   "metadata": {},
   "source": [
    "## Modeling (A part of training & validation process with 2011-2019 data)\n",
    "\n",
    "The values of y are all recorded as 0 for 2020 data. The actual values were not provided.\n",
    "\n",
    "Data from 2011-2019 was used for presenting a part of training & validation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85e61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sklearn.metrics\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c34abb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data and min-max normalizing\n",
    "data = pd.read_csv('data_210138.csv')\n",
    "data.iloc[:,6:193] = MinMaxScaler().fit_transform(data.iloc[:,6:193])\n",
    "\n",
    "data_part = data.loc[data['date'] < '2020-01-01',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a58a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_part.loc[data_part['date'].str.slice(stop=4) != '2019']\n",
    "data_val = data_part.loc[data_part['date'].str.slice(stop=4) == '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7714d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "# undersampling day1\n",
    "X0 = data_train.loc[data_train['X1day_yn']==0,]\n",
    "X1 = data_train.loc[data_train['X1day_yn']==1,]\n",
    "non, X0_samp = train_test_split(X0, random_state = 601, test_size=0.05, shuffle=True, stratify=X0['year'])\n",
    "data1 = pd.concat([X0_samp, X1])\n",
    "data1 = data1.drop(['year'], axis=1)\n",
    "\n",
    "# undersampling day2\n",
    "X0_2 = data_train.loc[data_train['X2day_yn']==0,]\n",
    "X1_2 = data_train.loc[data_train['X2day_yn']==1,]\n",
    "non, X0_samp2 = train_test_split(X0_2, random_state = 601, test_size=0.025, shuffle=True, stratify=X0_2['year'])\n",
    "data2 = pd.concat([X0_samp2, X1_2])\n",
    "data2 = data2.drop(['year'], axis=1) \n",
    "\n",
    "x1_t = data1.iloc[:,6:193] # training data for predicting the occurrence of landslide within 1day\n",
    "y1_t = data1.iloc[:,3]\n",
    "x2_t = data2.iloc[:,6:193] # train data for predicting the occurrence of landslide within 2days\n",
    "y2_t = data2.iloc[:,5]\n",
    "\n",
    "\n",
    "### Validation data\n",
    "# undersampling day1\n",
    "X0_v = data_val.loc[data_val['X1day_yn']==0,]\n",
    "X1_v = data_val.loc[data_val['X1day_yn']==1,]\n",
    "non_v, X0_v_samp = train_test_split(X0_v, random_state = 601, test_size=0.05, shuffle=True)\n",
    "data1_v = pd.concat([X0_v_samp, X1_v])\n",
    "data1_v = data1_v.drop(['year'], axis=1)\n",
    "\n",
    "# undersampling day2\n",
    "X0_v_2 = data_val.loc[data_val['X2day_yn']==0,]\n",
    "X1_v_2 = data_val.loc[data_val['X2day_yn']==1,]\n",
    "non_v, X0_v_samp2 = train_test_split(X0_v_2, random_state = 601, test_size=0.05, shuffle=True)\n",
    "data2_v = pd.concat([X0_v_samp2, X1_v_2])\n",
    "data2_v = data2_v.drop(['year'], axis=1)\n",
    "\n",
    "x1_v = data1_v.iloc[:,6:193] # validation data for predicting the occurrence of landslide within 1day\n",
    "y1_v = data1_v.iloc[:,3]\n",
    "x2_v = data2_v.iloc[:,6:193] # validation data for predicting the occurrence of landslide within 2days\n",
    "y2_v = data2_v.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31e056f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93316, 187)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b249138d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11717, 187)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4726ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1885b4ca",
   "metadata": {},
   "source": [
    "### Lasso regression - an example of predicting the occurrence of a landslide within 24-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f3163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5062f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr1 = LogisticRegression(C = 0.1, penalty='l1', solver='saga')\n",
    "logisticRegr1.fit(x1_t, y1_t)\n",
    "\n",
    "logisticRegr1_val = logisticRegr1.predict_proba(x1_v)[:,1]\n",
    "day1_lr = (logisticRegr1_val >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a33262d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11617     4]\n",
      " [   44    52]]\n",
      "0.9959033882393103\n"
     ]
    }
   ],
   "source": [
    "# CSI\n",
    "print(confusion_matrix(y1_v, day1_lr)) # 52/(4+44+52) = 0.52\n",
    "print(accuracy_score(y1_v, day1_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48786a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afe8e6bb",
   "metadata": {},
   "source": [
    "### LightGBM -  an example of predicting the occurrence of a landslide within 24-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ffc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39dcfcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 263, number of negative: 93053\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7080\n",
      "[LightGBM] [Info] Number of data points in the train set: 93316, number of used features: 171\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002818 -> initscore=-5.868770\n",
      "[LightGBM] [Info] Start training from score -5.868770\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "train_gbm1 = lgb.Dataset(x1_t, label=y1_t)\n",
    "params = {'learning_rate':0.01,\n",
    "          'max_depth':4,\n",
    "          'boosting':'gbdt',\n",
    "          'objective':'binary',\n",
    "          'metric':'binary_logloss',\n",
    "          'is_training_metric':True,\n",
    "          'num_leaves':20,\n",
    "          'feature_fraction':0.9,\n",
    "          'bagging_fraction':0.7,\n",
    "          'bagging_freq':10,\n",
    "          'seed':601}\n",
    "num_round = 100\n",
    "\n",
    "# training\n",
    "lgbm1 = lgb.train(params, train_gbm1, num_round)\n",
    "\n",
    "# validation\n",
    "lgbm1_val = lgbm1.predict(x1_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564dab43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11619     2]\n",
      " [   91     5]]\n",
      "0.9920628147136639\n"
     ]
    }
   ],
   "source": [
    "day1_lgbm = pd.Series(lgbm1_val).apply(lambda x: 1 if x>=0.5 else 0)\n",
    "\n",
    "# CSI\n",
    "print(confusion_matrix(y1_v, day1_lgbm)) # 5/(2+91+5) = 0.05\n",
    "print(accuracy_score(y1_v, day1_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622dbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13423294",
   "metadata": {},
   "source": [
    "### SVM - an example of predicting the occurrence of a landslide within 48-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c04e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3df6ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': [0.05,0.1], 'gamma': [10,1],'kernel': ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f36daf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] END .......................C=0.05, gamma=10, kernel=rbf; total time=  34.7s\n",
      "[CV] END .......................C=0.05, gamma=10, kernel=rbf; total time=  35.6s\n",
      "[CV] END .......................C=0.05, gamma=10, kernel=rbf; total time=  37.6s\n",
      "[CV] END .......................C=0.05, gamma=10, kernel=rbf; total time=  36.8s\n",
      "[CV] END .......................C=0.05, gamma=10, kernel=rbf; total time=  37.6s\n",
      "[CV] END ......................C=0.05, gamma=10, kernel=poly; total time=   3.0s\n",
      "[CV] END ......................C=0.05, gamma=10, kernel=poly; total time=   2.9s\n",
      "[CV] END ......................C=0.05, gamma=10, kernel=poly; total time=   3.1s\n",
      "[CV] END ......................C=0.05, gamma=10, kernel=poly; total time=   2.7s\n",
      "[CV] END ......................C=0.05, gamma=10, kernel=poly; total time=   2.9s\n",
      "[CV] END ...................C=0.05, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ...................C=0.05, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ...................C=0.05, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ...................C=0.05, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ...................C=0.05, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ........................C=0.05, gamma=1, kernel=rbf; total time=   3.5s\n",
      "[CV] END ........................C=0.05, gamma=1, kernel=rbf; total time=   3.8s\n",
      "[CV] END ........................C=0.05, gamma=1, kernel=rbf; total time=   3.5s\n",
      "[CV] END ........................C=0.05, gamma=1, kernel=rbf; total time=   3.8s\n",
      "[CV] END ........................C=0.05, gamma=1, kernel=rbf; total time=   3.6s\n",
      "[CV] END .......................C=0.05, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END .......................C=0.05, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END .......................C=0.05, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END .......................C=0.05, gamma=1, kernel=poly; total time=   2.2s\n",
      "[CV] END .......................C=0.05, gamma=1, kernel=poly; total time=   2.2s\n",
      "[CV] END ....................C=0.05, gamma=1, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END ....................C=0.05, gamma=1, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END ....................C=0.05, gamma=1, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END ....................C=0.05, gamma=1, kernel=sigmoid; total time=   2.7s\n",
      "[CV] END ....................C=0.05, gamma=1, kernel=sigmoid; total time=   2.1s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=  51.7s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=  53.1s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=  53.2s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=  52.6s\n",
      "[CV] END ........................C=0.1, gamma=10, kernel=rbf; total time=  52.4s\n",
      "[CV] END .......................C=0.1, gamma=10, kernel=poly; total time=   3.0s\n",
      "[CV] END .......................C=0.1, gamma=10, kernel=poly; total time=   2.9s\n",
      "[CV] END .......................C=0.1, gamma=10, kernel=poly; total time=   3.1s\n",
      "[CV] END .......................C=0.1, gamma=10, kernel=poly; total time=   2.6s\n",
      "[CV] END .......................C=0.1, gamma=10, kernel=poly; total time=   2.8s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   1.4s\n",
      "[CV] END ....................C=0.1, gamma=10, kernel=sigmoid; total time=   1.3s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   3.5s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   4.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   3.7s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   4.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   3.7s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   2.2s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   2.2s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   2.3s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   2.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   2.6s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   2.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.05, 0.1], 'gamma': [10, 1],\n",
       "                         'kernel': ['rbf', 'poly', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid = GridSearchCV(svm.SVC(), svm_param_grid, refit=True, verbose=2)\n",
    "svm_grid.fit(x2_t,y2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7d3576f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.05, gamma=10)\n"
     ]
    }
   ],
   "source": [
    "print(svm_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "423d74e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11621     0]\n",
      " [   96     0]]\n",
      "0.9918067764786208\n"
     ]
    }
   ],
   "source": [
    "day2_svm = svm_grid.predict(x2_v)\n",
    "print(confusion_matrix(y2_v, day2_svm)) # 0\n",
    "print(accuracy_score(y2_v, day2_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd7116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
